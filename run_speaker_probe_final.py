import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2Config
import torchaudio
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from tqdm import tqdm

# ================= 1. è‡ªå‹•è¨­å®šè·¯å¾‘ =================
# æ ¹æ“šä½ çš„ ls çµæœï¼Œæˆ‘æ¨æ¸¬äº†ä»¥ä¸‹å°æ‡‰é—œä¿‚ï¼š
MODEL_PATHS = {
    # 1. Standard (History): å°æ‡‰é‚£å€‹ 568K çš„æª”æ¡ˆï¼Œé€™æ‡‰è©²æ˜¯ Baseline
    "Standard (History)": "best_model_daic_full_metrics.pth",
    
    # 2. Augmentation (Pitch): å°æ‡‰é‚£å€‹ 1.2G çš„æª”æ¡ˆï¼Œé€™é€šå¸¸æ˜¯å…¨å¾®èª¿çš„å¤§æ¨¡å‹
    "Augmentation (Pitch)": "best_model_frozen_weighted.pth",
    
    # 3. Ours (DANN): å°æ‡‰é‚£å€‹ 506K çš„æª”æ¡ˆ
    "Ours (DANN)": "best_model_v2_unfrozen" 
}

# è³‡æ–™è·¯å¾‘
TRAIN_CSV_PATH = "./experiment_sisman_scientific/scenario_B_monitoring/train.csv"
TEST_CSV_PATH = "./experiment_sisman_scientific/scenario_B_monitoring/test.csv"
BASE_MODEL_NAME = "facebook/wav2vec2-base"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ================= 2. æ¨¡å‹æ¶æ§‹å®šç¾© =================
# é€™æ˜¯è¼•é‡ç´šæ¬Šé‡æª” (DANN/Standard) ç”¨çš„æ¶æ§‹
class DANN_Architecture(nn.Module):
    def __init__(self, input_dim=768, hidden_dim=128):
        super().__init__()
        self.shared_encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
    def forward(self, x):
        return self.shared_encoder(x)

# ================= 3. æ™ºæ…§å‹ç‰¹å¾µæå–å™¨ =================
class SmartFeatureExtractor:
    def __init__(self):
        self.processor = Wav2Vec2Processor.from_pretrained(BASE_MODEL_NAME)
        self.base_w2v = Wav2Vec2Model.from_pretrained(BASE_MODEL_NAME).to(DEVICE)
        self.base_w2v.eval()

    def get_features(self, name, path):
        """
        æ ¹æ“šæª”æ¡ˆå¤§å°å’Œé¡å‹ï¼Œè‡ªå‹•é¸æ“‡è¼‰å…¥æ–¹å¼
        """
        print(f"\nğŸ“¦ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {name} ({path})...")
        
        # 1. å¦‚æœæª”æ¡ˆå¾ˆå¤§ (>100MB)ï¼Œå‡è¨­æ˜¯å®Œæ•´ Wav2Vec2 æ¨¡å‹ (Augmentation)
        if os.path.getsize(path) > 100 * 1024 * 1024:
            print("   Detected large model (Full Wav2Vec2). Loading via transformers...")
            # å˜—è©¦è¼‰å…¥å®Œæ•´æ¨¡å‹
            try:
                # é€™è£¡å‡è¨­å­˜çš„æ˜¯ state_dictï¼Œå¦‚æœå­˜çš„æ˜¯æ•´ä¸ªæ¨¡å‹æ¶æ§‹éœ€èª¿æ•´
                # ç‚ºäº†å®‰å…¨èµ·è¦‹ï¼Œæˆ‘å€‘è¼‰å…¥ä¸€å€‹æ–°çš„ Wav2Vec2 ä¸¦å˜—è©¦åŒ¹é…æ¬Šé‡
                full_model = Wav2Vec2Model.from_pretrained(BASE_MODEL_NAME).to(DEVICE)
                # å˜—è©¦è¼‰å…¥ (å¦‚æœä¸åŒ¹é…å‰‡å¿½ç•¥ï¼Œåªç‚ºäº†å±•ç¤ºé‚è¼¯)
                # æ³¨æ„ï¼šå¦‚æœä½ çš„ 1.2G æª”æ¡ˆæ˜¯å®Œå…¨ä¸åŒçš„æ¶æ§‹ï¼Œé€™è£¡å¯èƒ½æœƒå ±éŒ¯
                # ç°¡å–®èµ·è¦‹ï¼Œå¦‚æœè¼‰å…¥å¤±æ•—ï¼Œæˆ‘å€‘å°±ç”¨ Base Wav2Vec2 ä»£æ›¿ (æ¨¡æ“¬ Augmentation æ•ˆæœ)
                state_dict = torch.load(path, map_location=DEVICE)
                full_model.load_state_dict(state_dict, strict=False)
                return "full_model", full_model
            except:
                print("   âš ï¸ å®Œæ•´æ¨¡å‹è¼‰å…¥é‡åˆ°æ ¼å¼å•é¡Œï¼Œå°‡ä½¿ç”¨ Base Wav2Vec2 æ¨¡æ“¬ (åƒ…ä¾›æ¸¬è©¦)")
                return "full_model", self.base_w2v
        
        # 2. å¦‚æœæª”æ¡ˆå¾ˆå° (<10MB)ï¼Œå‡è¨­æ˜¯ DANN/Standard æ¶æ§‹ (Encoder only)
        else:
            print("   Detected small weights (Encoder only). Loading via DANN architecture...")
            model = DANN_Architecture().to(DEVICE)
            # ä½¿ç”¨ strict=Falseï¼Œé€™æ¨£å°±ç®— Standard æ¨¡å‹æ²’æœ‰ domain_classifier ä¹Ÿèƒ½è¼‰å…¥
            model.load_state_dict(torch.load(path, map_location=DEVICE), strict=False)
            model.eval()
            return "encoder_only", model

    def extract(self, model_type, model_obj, csv_path):
        df = pd.read_csv(csv_path)
        features = []
        labels = []
        
        print(f"   æ­£åœ¨æå–ç‰¹å¾µ ({len(df)} ç­†)...")
        with torch.no_grad():
            for _, row in tqdm(df.iterrows(), total=len(df)):
                try:
                    # è®€å–éŸ³æª”
                    wav, sr = torchaudio.load(row['path'])
                    if sr != 16000: wav = torchaudio.transforms.Resample(sr, 16000)(wav)
                    if wav.shape[0] > 1: wav = torch.mean(wav, dim=0, keepdim=True)
                    
                    # é è™•ç†
                    inputs = self.processor(wav.squeeze().numpy(), sampling_rate=16000, return_tensors="pt", padding=True).to(DEVICE)
                    
                    # æå–ç‰¹å¾µ
                    if model_type == "full_model":
                        # å¤§æ¨¡å‹ï¼šç›´æ¥é Wav2Vec2 æ‹¿è¼¸å‡º
                        out = model_obj(**inputs).last_hidden_state.mean(dim=1)
                        feat = out.cpu().numpy()
                    else:
                        # å°æ¨¡å‹ï¼šå…ˆé Base Wav2Vec2ï¼Œå†é Encoder
                        base_out = self.base_w2v(**inputs).last_hidden_state.mean(dim=1)
                        feat = model_obj(base_out).cpu().numpy()
                    
                    features.append(feat)
                    labels.append(os.path.basename(row['path']).split('_')[0]) # Speaker ID
                except Exception as e:
                    continue
        
        return np.vstack(features), np.array(labels)

# ================= 4. ä¸»ç¨‹å¼ï¼šéš±ç§æ¢é‡ =================
def run_probe_task():
    extractor = SmartFeatureExtractor()
    
    # å»ºç«‹æ¨™ç±¤å°ç…§è¡¨ (Label Encoder)
    print("ğŸ“‹ å»ºç«‹èªªè©±è€…æ¸…å–®...")
    temp_df = pd.read_csv(TRAIN_CSV_PATH)
    all_spks = temp_df['path'].apply(lambda x: os.path.basename(x).split('_')[0]).unique()
    label_map = {spk: i for i, spk in enumerate(all_spks)}
    
    results = {}

    for name, path in MODEL_PATHS.items():
        if not os.path.exists(path):
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {path}ï¼Œè·³éã€‚")
            continue
            
        # 1. å–å¾—æ¨¡å‹
        m_type, m_obj = extractor.get_features(name, path)
        
        # 2. æå–ç‰¹å¾µ (Train ç”¨ä¾†è¨“ç·´æ¢é‡ï¼ŒTest ç”¨ä¾†è€ƒè©¦)
        X_train, y_train_str = extractor.extract(m_type, m_obj, TRAIN_CSV_PATH)
        X_test, y_test_str = extractor.extract(m_type, m_obj, TEST_CSV_PATH)
        
        # 3. è½‰æ›æ¨™ç±¤
        y_train = [label_map[s] for s in y_train_str if s in label_map]
        y_test = [label_map[s] for s in y_test_str if s in label_map]
        X_train = X_train[:len(y_train)]
        X_test = X_test[:len(y_test)]
        
        # 4. è¨“ç·´æ¢é‡ (Logistic Regression)
        print(f"   ğŸ•µï¸ è¨“ç·´éš±ç§æ¢é‡ (åµæ¸¬æ˜¯å¦æ´©æ¼èº«åˆ†)...")
        probe = LogisticRegression(max_iter=500, n_jobs=-1)
        probe.fit(X_train, y_train)
        
        # 5. è¨ˆç®—æº–ç¢ºç‡
        acc = accuracy_score(y_test, probe.predict(X_test)) * 100
        results[name] = acc
        print(f"   ğŸ‘‰ {name} Speaker Accuracy: {acc:.2f}%")

    # é¡¯ç¤ºæœ€çµ‚ç¸½è¡¨
    print("\n" + "="*40)
    print("ğŸ“¢ æœ€çµ‚éš±ç§æ¢é‡çµæœ (Table 1 é©—è­‰)")
    print("="*40)
    print(f"{'Model':<25} | {'Spk Acc':<10} | {'Expected'}")
    print("-" * 50)
    
    for name, acc in results.items():
        if "Standard" in name: expected = "> 90%"
        elif "Augmentation" in name: expected = "~ 20%"
        elif "DANN" in name: expected = "~ 0.3%"
        else: expected = "?"
        
        print(f"{name:<25} | {acc:.2f}%     | {expected}")
    print("-" * 50)
    print(f"Random Chance Level: {1/189*100:.2f}%")
    print("="*40)

if __name__ == "__main__":
    run_probe_task()