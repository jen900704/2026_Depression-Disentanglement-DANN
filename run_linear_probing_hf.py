import os
import argparse
import yaml
import torch
import numpy as np
from datasets import load_from_disk
from transformers import Wav2Vec2Model
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from tqdm import tqdm

def run_linear_probing(config_path):
    with open(config_path) as f:
        config = yaml.load(f, Loader=yaml.FullLoader)

    features_path = os.path.join(config['output_dir'], 'features')
    train_dir = os.path.join(features_path, "train_dataset")
    eval_dir = os.path.join(features_path, "eval_dataset")

    try:
        train_dataset = load_from_disk(train_dir)
        eval_dataset = load_from_disk(eval_dir)
    except Exception as e:
        print(f"âŒ è®€å–è³‡æ–™é›†å¤±æ•—: {e}")
        return

    # 1. å–šé†’ Wav2Vec2 æ¨¡å‹ä¾†ç•¶ã€Œç‰¹å¾µæŠ½å–å™¨ã€
    print("ğŸ§  æ­£åœ¨è¼‰å…¥ Wav2Vec2 æ¨¡å‹æå–æ·±å±¤ç‰¹å¾µ (Embeddings)...")
    
    # è‡ªå‹•åµæ¸¬æ˜¯å¦æœ‰ GPU å¯ä»¥åŠ é€Ÿ
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸ é‹ç®—è¨­å‚™: {device}")
    
    model_name = config.get('processor_name_or_path', 'facebook/wav2vec2-base')
    model = Wav2Vec2Model.from_pretrained(model_name).to(device)
    model.eval() # é–å®šæ¨¡å‹ï¼Œä¸æ›´æ–°æ¬Šé‡

    # 2. å®šç¾©æŠ½å–å‡½æ•¸
    def get_embeddings(dataset):
        embeddings = []
        labels = []
        for item in tqdm(dataset, desc="æŠ½å–ç‰¹å¾µä¸­"):
            # å–å‡ºåŸå§‹æ³¢å½¢ï¼Œè½‰æˆ tensor ä¸¦ä¸Ÿåˆ° GPU/CPU
            input_values = torch.tensor(item['input_values']).unsqueeze(0).to(device)
            if input_values.shape[1] == 0: continue
            
            with torch.no_grad(): # çœè¨˜æ†¶é«”å¤§æ³•
                outputs = model(input_values)
                # å–å‡ºæœ€å¾Œä¸€å±¤çš„ç‰¹å¾µï¼Œä¸¦å°æ™‚é–“è»¸åšå¹³å‡ (Global Average Pooling) -> è®Šæˆ 768 ç¶­
                hidden_state = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()
            
            embeddings.append(hidden_state)
            labels.append(item['labels'])
        return np.array(embeddings), np.array(labels)

    # 3. é–‹å§‹æŠ½å–
    print("\nâ³ è½‰æ›ã€è¨“ç·´é›†ã€‘ (é€™éœ€è¦ä¸€é»æ™‚é–“)...")
    X_train, y_train = get_embeddings(train_dataset)
    print("\nâ³ è½‰æ›ã€æ¸¬è©¦é›†ã€‘...")
    X_test, y_test = get_embeddings(eval_dataset)

    print(f"\nâœ… æˆåŠŸç²å¾—æ·±å±¤ç‰¹å¾µï¼é€²å…¥ Linear Probing æ¨¡å‹å½¢ç‹€: X_train={X_train.shape}")
    
    # 4. çœŸæ­£å…¬å¹³çš„å°æ±ºï¼šLogistic Regression
    print("\nğŸš€ é–‹å§‹åŸ·è¡Œ Linear Probing...")
    clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    print("\n" + "="*40)
    print("ğŸ¯ Linear Probing æ¸¬è©¦é›†çµæœ")
    print("="*40)
    print(classification_report(y_test, y_pred, zero_division=0))
    print("æ··æ·†çŸ©é™£:\n", confusion_matrix(y_test, y_pred))

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', required=True)
    args = parser.parse_args()
    run_linear_probing(args.config)