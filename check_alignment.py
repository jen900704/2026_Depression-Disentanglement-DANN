"""
å°é½Šæª¢æŸ¥è…³æœ¬ v2 â€” åªæª¢æŸ¥ 16 å€‹è¨“ç·´è…³æœ¬
ç”¨æ³•ï¼špython check_alignment_v2.py /path/to/training_scripts/
"""
import os, sys, ast, re

# ============================================================
# åªæƒé€™ 16 å€‹æª”æ¡ˆï¼ˆç²¾ç¢ºæ¯”å°ï¼‰
# ============================================================
TARGET_FILES = {
    # Huang A/B (v2)
    "replicate_huang_scenario_a_v2.py",
    "replicate_huang_scenario_b_v2.py",
    # DANN static A/B
    "run_dann_a_v2.py",
    "run_dann_b_v2.py",
    # DANN finetune A/B
    "run_dann_finetune_a.py",
    "run_dann_finetune_b.py",
    # SLS no-finetune A/B
    "huang_sls_a.py",
    "huang_sls_b.py",
    # SLS finetune A/B  (æœ‰äº›å« huang_sls_ft_A / huang_sls_dann_finetune_A)
    "huang_sls_ft_a.py",
    "huang_sls_ft_b.py",
    "huang_sls_dann_finetune_a.py",
    "huang_sls_dann_finetune_b.py",
    # XLSR no-finetune A/B
    "xlsr_egemaps_a.py",
    "xlsr_egemaps_b.py",
    # XLSR finetune A/B
    "xlsr_egemaps_dann_finetune_a.py",
    "xlsr_egemaps_dann_finetune_b.py",
    # SLS+DANN no-finetuneï¼ˆä½ å·²é€šéçš„ç‰ˆæœ¬ï¼Œä¿ç•™åš referenceï¼‰
    "huang_sls_dann_a.py",
    "huang_sls_dann_b.py",
}


def get_training_args_block(src):
    """æ“·å– TrainingArguments(...) çš„å…§å®¹ã€‚"""
    start = src.find("TrainingArguments(")
    if start == -1:
        return ""
    depth, end = 0, start
    for i, ch in enumerate(src[start:], start):
        if ch == "(": depth += 1
        elif ch == ")":
            depth -= 1
            if depth == 0:
                end = i; break
    return src[start:end+1]


def check_file(filepath):
    with open(filepath) as f:
        src = f.read()
    fname  = os.path.basename(filepath).lower()
    issues, ok_list = [], []

    def chk(label, cond, fix=""):
        (ok_list if cond else issues).append(
            ("âœ… " if cond else "âŒ ") + label + (f"  â†’  {fix}" if not cond and fix else "")
        )

    args_block = get_training_args_block(src)

    # 1. SEED = 103
    m = re.search(r'^SEED\s*=\s*(\d+)', src, re.MULTILINE)
    chk("SEED=103", m and m.group(1) == "103", "SEED = 103")

    # 2. EVAL/SAVE/LOGGING_STEPS = 10
    for step in ["EVAL_STEPS", "SAVE_STEPS", "LOGGING_STEPS"]:
        m = re.search(rf'^{step}\s*=\s*(\d+)', src, re.MULTILINE)
        chk(f"{step}=10", m and m.group(1) == "10", f"{step} = 10")

    # 3. run seed = SEED + run_i - 1
    chk("run seed=103-107",
        "SEED + run_i - 1" in src,
        "run_seed = SEED + run_i - 1")

    # 4. eval_dataset = test_datasetï¼ˆé split validï¼‰
    chk("eval_dataset=test_dataset",
        "eval_dataset=test_dataset" in src,
        "eval_dataset=test_dataset ï¼ˆä¸åˆ‡ valid splitï¼‰")

    # 5. ç„¡ metric_for_best_modelï¼ˆTrainingArguments è£¡ï¼‰
    metric_line = re.search(r'metric_for_best_model\s*=', args_block)
    is_comment  = metric_line and args_block[max(0, metric_line.start()-2):metric_line.start()].strip().endswith("#")
    chk("ç„¡ metric_for_best_model",
        metric_line is None or is_comment,
        "ç§»é™¤ metric_for_best_modelï¼ˆé è¨­ eval_lossï¼‰")

    # 6. pth å„²å­˜ï¼ˆdown_proj.state_dictï¼‰
    chk("pth å„²å­˜ down_proj",
        "down_proj.state_dict()" in src,
        "torch.save(trainer.model.down_proj.state_dict(), pth_path)")

    # 7. pth æª”åå«æ­£ç¢º A_ æˆ– B_
    if fname.endswith("_a.py"):
        match_a = bool(re.search(r'_A_shared_encoder|_A_encoder', src))
        match_b = bool(re.search(r'_B_shared_encoder|_B_encoder', src))
        chk("pth æª”åå« _A_ï¼ˆé_B_ï¼‰",
            match_a and not match_b,
            "pth è·¯å¾‘æ‡‰å« _A_ï¼Œä¸èƒ½å« _B_")
    elif fname.endswith("_b.py"):
        match_a = bool(re.search(r'_A_shared_encoder|_A_encoder', src))
        match_b = bool(re.search(r'_B_shared_encoder|_B_encoder', src))
        chk("pth æª”åå« _B_ï¼ˆé_A_ï¼‰",
            match_b and not match_a,
            "pth è·¯å¾‘æ‡‰å« _B_ï¼Œä¸èƒ½å« _A_")

    # 8. summary_5runs.csv
    chk("summary_5runs.csv",
        "summary_5runs.csv" in src,
        "results_df.to_csv(os.path.join(OUTPUT_DIR, 'summary_5runs.csv'), index=False)")

    # 9. results["run"] = run_i
    chk('results["run"]=run_i',
        'results["run"] = run_i' in src or "results['run'] = run_i" in src,
        'results["run"] = run_i')

    # 10. gc.collect
    chk("gc.collect()",
        "gc.collect()" in src,
        "del model, trainer; torch.cuda.empty_cache(); gc.collect()")

    # 11. ç„¡ dataloader_drop_lastï¼ˆTrainingArguments è£¡ï¼‰
    drop_line = re.search(r'dataloader_drop_last\s*=', args_block)
    is_comment = drop_line and args_block[max(0, drop_line.start()-2):drop_line.start()].strip().endswith("#")
    chk("ç„¡ dataloader_drop_last",
        drop_line is None or is_comment,
        "ç§»é™¤ dataloader_drop_last=True")

    # 12. Scenario è·¯å¾‘ä¸€è‡´
    if "_a.py" in fname:
        chk("CSV è·¯å¾‘å« scenario_A",
            "scenario_A_screening" in src,
            "TRAIN/TEST_CSV æ‡‰å« scenario_A_screening")
    elif "_b.py" in fname:
        chk("CSV è·¯å¾‘å« scenario_B",
            "scenario_B_monitoring" in src,
            "TRAIN/TEST_CSV æ‡‰å« scenario_B_monitoring")

    # 13. XLS-R backbone
    if "xlsr" in fname:
        chk("XLS-R backbone",
            "wav2vec2-xls-r-300m" in src or "xls-r" in src.lower(),
            'MODEL_NAME = "facebook/wav2vec2-xls-r-300m"')

    # 14. spk_classifier é hardcode 200
    if "spk_classifier" in src and "nn.Linear(128," in src:
        chk("spk_classifier é hardcode 200",
            "Linear(128, 200)" not in src,
            "nn.Linear(128, getattr(config, 'num_speakers', ...))")

    # 15. èªæ³•
    try:
        ast.parse(src); ok_list.append("âœ… èªæ³•åˆæ³•")
    except SyntaxError as e:
        issues.append(f"âŒ èªæ³•éŒ¯èª¤: {e}")

    return ok_list, issues


def main():
    search_dir = sys.argv[1] if len(sys.argv) > 1 else "."
    all_py = [f for f in os.listdir(search_dir) if f.endswith(".py")]
    matched = [f for f in all_py if f.lower() in TARGET_FILES]
    missing = [t for t in TARGET_FILES if t not in [f.lower() for f in all_py]]

    print(f"\n{'='*65}")
    print(f"ğŸ” å°é½Šæª¢æŸ¥ v2 â€” è¨“ç·´è…³æœ¬å°ˆç”¨")
    print(f"   æƒæç›®éŒ„ï¼š{search_dir}")
    print(f"   æ‰¾åˆ° {len(matched)}/{len(TARGET_FILES)} å€‹ç›®æ¨™æª”æ¡ˆ")
    print(f"{'='*65}\n")

    if missing:
        print(f"âš ï¸  ä»¥ä¸‹ {len(missing)} å€‹ç›®æ¨™æª”æ¡ˆä¸å­˜åœ¨ï¼š")
        for f in sorted(missing):
            print(f"  â“ {f}")
        print()

    clean, dirty = [], []
    for fname in sorted(matched):
        fpath = os.path.join(search_dir, fname)
        ok_list, issues = check_file(fpath)
        if issues:
            dirty.append((fname, issues))
        else:
            clean.append(fname)

    if dirty:
        print(f"âš ï¸  ä»¥ä¸‹ {len(dirty)} å€‹æª”æ¡ˆæœ‰å•é¡Œï¼š\n")
        for fname, issues in dirty:
            print(f"  ğŸ“„ {fname}")
            for iss in issues:
                print(f"      {iss}")
            print()

    if clean:
        print(f"âœ… ä»¥ä¸‹ {len(clean)} å€‹æª”æ¡ˆå…¨éƒ¨é€šéï¼š")
        for f in clean:
            print(f"  âœ… {f}")

    print(f"\n{'='*65}")
    print(f"ğŸ“Š {len(clean)}/{len(matched)} é€šé  |  {len(dirty)} æœ‰å•é¡Œ  |  {len(missing)} ä¸å­˜åœ¨")
    print(f"{'='*65}")


if __name__ == "__main__":
    main()